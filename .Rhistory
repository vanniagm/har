theme_minimal(base_size = base_size, base_family = base_family) +
theme(
axis.text = element_text(size = 12),
axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.5),
axis.title = element_text(size = 14),
panel.grid.major = element_line(color = "grey"),
panel.grid.minor = element_blank(),
panel.background = element_rect(fill = "aliceblue"),
strip.background = element_rect(fill = "lightgrey", color = "grey", size = 1),
strip.text = element_text(face = "bold", size = 12, color = "black"),
legend.position = "bottom",
legend.justification = "top",
legend.box = "horizontal",
legend.background = element_blank(),
panel.border = element_rect(color = "grey", fill = NA, size = 0.5)
)
}
p1<-ggplot(data=fluH7N9_china_2013_gather2,aes(x=value,fill=outcome,color=outcome))+
geom_bar(alpha=.7,size=1)+gral_theme+
scale_fill_brewer(palette="Set1", na.value = "grey50") +
scale_color_brewer(palette="Set1", na.value = "grey50") +
labs(
color = "",
fill = "",
x = "",
y = "Count",
title = "2013 Influenza A H7N9 cases in China",
subtitle = "Gender and Province numbers of flu cases",
caption = ""
)
p2<-ggplot(data=fluH7N9_china_2013_gather,aes(x=as.numeric(age),fill=outcome,color=outcome))+
geom_density(alpha=.4,size=1)+
gral_theme+
scale_color_brewer(palette="Set1", na.value = "grey50") +
scale_fill_brewer(palette="Set1", na.value = "grey50") +
labs(
color = "",
fill = "",
x = "Age",
y = "Density",
title = "",
subtitle = "Age distribution of flu cases",
caption = ""
)
library(gridExtra)
library(grid)
grid.arrange(p1, p2, ncol = 2)
p1<-ggplot(data=fluH7N9_china_2013_gather2,aes(x=value,fill=outcome,color=outcome))+
geom_bar(alpha=.7,size=1)+gral_theme()+
scale_fill_brewer(palette="Set1", na.value = "grey50") +
scale_color_brewer(palette="Set1", na.value = "grey50") +
labs(
color = "",
fill = "",
x = "",
y = "Count",
title = "2013 Influenza A H7N9 cases in China",
subtitle = "Gender and Province numbers of flu cases",
caption = ""
)
p2<-ggplot(data=fluH7N9_china_2013_gather,aes(x=as.numeric(age),fill=outcome,color=outcome))+
geom_density(alpha=.4,size=1)+
gral_theme()+
scale_color_brewer(palette="Set1", na.value = "grey50") +
scale_fill_brewer(palette="Set1", na.value = "grey50") +
labs(
color = "",
fill = "",
x = "Age",
y = "Density",
title = "",
subtitle = "Age distribution of flu cases",
caption = ""
)
library(gridExtra)
library(grid)
grid.arrange(p1, p2, ncol = 2)
p1<-ggplot(data=fluH7N9_china_2013_gather2,aes(x=value,fill=outcome,color=outcome))+
geom_bar(position="dodge",alpha=.7,size=1)+gral_theme()+
scale_fill_brewer(palette="Set1", na.value = "grey50") +
scale_color_brewer(palette="Set1", na.value = "grey50") +
labs(
color = "",
fill = "",
x = "",
y = "Count",
title = "2013 Influenza A H7N9 cases in China",
subtitle = "Gender and Province numbers of flu cases",
caption = ""
)
p2<-ggplot(data=fluH7N9_china_2013_gather,aes(x=as.numeric(age),fill=outcome,color=outcome))+
geom_density(alpha=.4,size=1)+
gral_theme()+
scale_color_brewer(palette="Set1", na.value = "grey50") +
scale_fill_brewer(palette="Set1", na.value = "grey50") +
labs(
color = "",
fill = "",
x = "Age",
y = "Density",
title = "",
subtitle = "Age distribution of flu cases",
caption = ""
)
library(gridExtra)
library(grid)
grid.arrange(p1, p2, ncol = 2)
head(fluH7N9_china_2013_gather)
ggplot(data = fluH7N9_china_2013_gather, aes(x = Date, y = as.numeric(age), color = outcome)) +
geom_point(aes(shape = gender), size = 1.5, alpha = 0.6) +
geom_path(aes(group = case.ID)) +
facet_wrap( ~ province, ncol = 2) +
gral_theme()
ggplot(data = fluH7N9_china_2013_gather, aes(x = Date, y = as.numeric(age), color = outcome)) +
geom_point(aes(shape = gender), size = 1.5, alpha = 0.6) +
facet_wrap( ~ province, ncol = 2) +
gral_theme()
head(fluH7N9_china_2013_gather)
head(fluH7N9_china_2013_gather[fluH7N9_china_2013_gather$case_id=="case_1",])
head(fluH7N9_china_2013)
ggplot(data = fluH7N9_china_2013_gather, aes(x = Date, y = as.numeric(age), color = outcome)) +
geom_point(aes(shape = gender), size = 1.5, alpha = 0.6) +geom_path()+
facet_wrap( ~ province, ncol = 2) +
gral_theme()
ggplot(data = fluH7N9_china_2013_gather, aes(x = Date, y = as.numeric(age), color = outcome)) +
geom_point(aes(shape = gender), size = 1.5, alpha = 0.6) +geom_path(aes(group=case.ID))+
facet_wrap( ~ province, ncol = 2) +
gral_theme()
ggplot(data = fluH7N9_china_2013_gather, aes(x = Date, y = as.numeric(age), color = outcome)) +
geom_point(aes(shape = gender), size = 1.5, alpha = 0.6) +geom_path(aes(group=case_id))+
facet_wrap( ~ province, ncol = 2) +
gral_theme()
R.version()
R.version
library(plotly)
set.seed(100)
d <- diamonds[sample(nrow(diamonds), 1000), ]
plot_ly(d, x = carat, y = price, text = paste("Clarity: ", clarity),
mode = "markers", color = carat, size = carat)
install.packages("devtools")
library(devtools)
install.packages('ggplot2')
install.packages('lubridate')
install.packages('dplyr')
install.packages('plyr')
install.packages('reshape')
library('plotly')
devtools::install_github("ropensci/plotly")
install.packages('datasets')
install.packages("datasets")
install.packages("datasets")
library(datasets)
library(plotly)
set.seed(100)
d <- diamonds[sample(nrow(diamonds), 1000), ]
plot_ly(d, x = carat, y = price, text = paste("Clarity: ", clarity),
mode = "markers", color = carat, size = carat)
library('datasets')
library(plotly)
set.seed(100)
d <- diamonds[sample(nrow(diamonds), 1000), ]
plot_ly(d, x = carat, y = price, text = paste("Clarity: ", clarity),
mode = "markers", color = carat, size = carat)
library('data')
data("diamonds")
d <- diamonds[sample(nrow(diamonds), 1000), ]
plot_ly(d, x = carat, y = price, text = paste("Clarity: ", clarity),
+         mode = "markers", color = carat, size = carat)
plot_ly(d, x = carat, y = price, text = paste("Clarity: ", clarity),mode = "markers", color = carat, size = carat)
str(diamonds)
plot_ly(d, x = carat, y = price, text = paste("Clarity: ", clarity),mode = "markers", color = carat, size = carat)
str(d)
p <- ggplot(data = d, aes(x = carat, y = price)) +
geom_point(aes(text = paste("Clarity:", clarity)), size = 4) +
geom_smooth(aes(colour = cut, fill = cut)) + facet_wrap(~ cut)
(gg <- ggplotly(p))
devtools::install_github('hadley/ggplot2')
p <- ggplot(data = d, aes(x = carat, y = price)) +
geom_point(aes(text = paste("Clarity:", clarity)), size = 4) +
geom_smooth(aes(colour = cut, fill = cut)) + facet_wrap(~ cut)
(gg <- ggplotly(p))
library(slidify)
slidify(Index.html)
.99/(.99+.999)
.99/(.99+9.99)
.99/(.99+99.99)
library(caret)
library(kernlab);data(spam)
intrain<-createDataPartition(y=spam$type,p=0.75,list=FALSE)
training<-spam[intrain,]
test<-spam[-intrain,]
hist(training$capitalAve)
traincapAv<-training$capitalAve
traincapAv<-(traincapAv-mean(traincapAv))/sd(traincapAv)
mean(traincapAv)
sd(traincapAv)
hist(spam$traincapAv)
hist(traincapAv)
preObj<-preProcess(training[,-58],method=c("center","scale"))
traincapAvS<-predict(preOcj,training[,-58]$capitalAve)
traincapAvS<-predict(preObj,training[,-58]$capitalAve)
dim(preObj)
preObj<-preProcess(training[,-58],method=c("center","scale"))
traincapAvS<-predict(preObj,training[,-58])$capitalAve
mean(traincapAvS)
preObj<-preProcess(training[,-58],method=c("center","scale"))
traincapAvS<-predict(preObj,training[,-58])$capitalAve
mean(traincapAvS)
preObj<-preProcess(training[,-58],method=c("BoxCox"))
traincapAvS<-predict(preObj,training[,-58])$capitalAve
hist(traincapAvS)
qqnorm(traincapAvS)
training$capAve<-training$capitalAve
selectNA<-rbinom(dim(training)[1],size=1,prob=.5)==1
head(selectNA)
trainin$capAve[selectNA]<-NA
training$capAve[selectNA]<-NA
preobj<-preProcess(training[,-58],method="knnImpute")
capAve<-predict(preObj,training[,-58])$capAve
capAveTruth<-training$capitalAve
capAveTruth<-(capAveTruth-mean(capAveTruth))/sd(capAveTruth)
library(ISLR);data("Wage")
install.packages(ISLR)
install.packages('ISLR')
library(ISLR);data("Wage")
inTrain<-createDataPartition(y=Wage$wage,p=.7,list=FALSE)
training<-Wage[inTrain,];testing<-Wage[-inTrain,]
library(mlbench)
install.packages('mlbench')
library(mlbench)
data("Sonar")
head(sonar)
head(Sonar)
data(iris); library(ggplot2)
names(iris)
library(caret)
inTrain<-createDataPartition(y=iris$Species,p=.7,list=FALSE)
training<-iris[,inTrain]
training<-iris[inTrain,]
testing<-iris[-inTrain,]
dim(training);dim(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
modFit<-train(Species~.,method='rpart',data=training)
pprint(modFit$finalModel)
print(modFit$finalModel)
plot(modFit$finalModel,uniform=TRUE)
text(modFit$finalModel,use.n=TRUE)
text(modFit$finalModel,use.n=TRUE,all=TRUE)
library(rattle)
fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata=testing)
confusionMatrix(testing$Species,predict(modFit,nesdata=testing))
confusionMatrix(testing$Species,predict(modFit,newdata=testing))
library(ElemStatLearn)
install.packages("ElemStatLearn")
ozone<-ozone[order(ozonoe$ozone),]
library(ElemStatLearn)
data(ozone,package = 'ElementStatLearn')
data(ozone,package = 'ElemStatLearn')
ozone<-ozone[order(ozonoe$ozone),]
ozone<-ozone[order(ozono$ozone),]
ozone<-ozone[order(ozone$ozone),]
head(ozone)
str(ozone)
ll<-matrix(NA,nrow=10,ncol=155)
for(i in 1:10){ss<-sample(i:dim(ozone))[1],replace=T,}
for(i in 1:10){ss<-sample(i:dim(ozone))[1],replace=T;}
dim(ozone)[1]
names(ozone)
for(i in 1:10){
ss<-sample(1:dim(ozone))[1],replace=T
ozone0<-ozone[ss,];ozone0<ozone0[order(ozone0$ozone),]
loess0<-loess(temperature~ozone,data=ozone0,span=.2)
ll[i,]<-predict(loess0,newdata=data.frame(ozone=1:155))
}
for(i in 1:10){
ss<-sample(1:dim(ozone))[1],replace=T
ozone0<-ozone[ss,];ozone0<ozone0[order(ozone0$ozone),]
loess0<-loess(temperature~ozone,data=ozone0,span=.2)
ll[i,]<-predict(loess0,newdata=data.frame(ozone=1:155))
}
for(i in 1:10){
ss<-sample(1:dim(ozone))[1],replace=T
ozone0<-ozone[ss,];ozone0<ozone0[order(ozone0$ozone),]
loess0<-loess(temperature~ozone,data=ozone0,span=.2)
ll[i,]<-predict(loess0,newdata=data.frame(ozone=1:155))
}
for(i in 1:10){
ss<-sample(1:dim(ozone))[1],replace=T)
ozone0<-ozone[ss,];ozone0<ozone0[order(ozone0$ozone),]
loess0<-loess(temperature~ozone,data=ozone0,span=.2)
ll[i,]<-predict(loess0,newdata=data.frame(ozone=1:155))
}
for(i in 1:10){
ss<-sample(1:dim(ozone))[1],replace=T)
ozone0<-ozone[ss,];ozone0<-ozone0[order(ozone0$ozone),]
loess0<-loess(temperature~ozone,data=ozone0,span=.2)
ll[i,]<-predict(loess0,newdata=data.frame(ozone=1:155))
}
for(i in 1:10){
ss<-sample(1:dim(ozone))[1],replace=T)
ozone0<-ozone[ss,];ozone0<-ozone0[order(ozone0$ozone),]
loess0<-loess(temperature~ozone,data=ozone0,span=.2)
ll[i,]<-predict(loess0,newdata=data.frame(ozone=1:155))
}
for(i in 1:10){
ss<-sample(1:dim(ozone)[1],replace=T)
ozone0<-ozone[ss,];ozone0<-ozone0[order(ozone0$ozone),]
loess0<-loess(temperature~ozone,data=ozone0,span=.2)
ll[i,]<-predict(loess0,newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone,ozone$temperature)
for(i in 10){lines(1:155,ll[i,]col='grey',lwd=2)}
for(i in 10){lines(1:155,ll[i,],col='grey',lwd=2)}
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
apply(ll,2,mean)
head(ll)
ll[1,]
ll[10,]
head(onone$ozone)
head(ozone$ozone)
?classcenter
?classCenter
library(caret)
classCenter()
install.packages('RandomForests')
install.packages('RandomForest')
install.packages('randomForest')
?classCenter
library('randomForest')
?classCenter
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
intrain<-createDataPartition(y=segmentationOriginal$Case,p=.7,list=FALSE)
set.seed(125)
training<-segmentationOriginal[intrain,]
testing<-segmentationOriginal[-intrain,]
modelFit<-train(Case~.,method=rpart,data=training)
names(training)
modelFit<-train(Case~.,method='rpart',data=training)
modelFit$finalModel
library(rattle)
fancyRpartPlot(modelFit$finalModel)
training<-segmentationOriginal[Case=='train',]
training<-segmentationOriginal[segmentationOriginal$Case=='train',]
names(training)
training<-segmentationOriginal[segmentationOriginal$Case=='test',]
training<-segmentationOriginal[segmentationOriginal$Case=='train',]
testing<-segmentationOriginal[segmentationOriginal$Case=='test',]
head(segmentationOriginal$Case)
set.seed(125)
modelFit<-train(Class~.,method='rpart',data=training)
training<-segmentationOriginal[segmentationOriginal$Case=='Train',]
testing<-segmentationOriginal[segmentationOriginal$Case=='Test',]
modelFit<-train(Class~.,method='rpart',data=training)
fancyRpartPlot(modelFit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages(pgmm)
install.packages('pgmm')
install.packages('pgmm')
library(pgmm)
data(olive)
olive = olive[,-1]
head(olive)
intrain<-createDataPartition(y=olive$Area,p=.7,list=FALSE)
training<-olive[intrain,]
testing<-olive[-intrain,]
modelfit<-train(Area~.,method='rpart',data=training)
fancyRpartPlot(modelfit$finalModel)
predict(modelfit,newdata = as.data.frame(t(colMeans(olive))))
head(area)
levels(training$Area)
class(training$Area)
hist(training$Area)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(1234)
names(trainSA)
modelfit<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=training,method='glm',famili='binomial')
modelfit<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method='glm',famili='binomial')
modelfit<-train(y=chd,x=c('age','alcohol','obesity','tobacco','typea','ldl'),data=trainSA,method='glm',famili='binomial')
modelfit<-train(y=chd,x=c(ag,alcohol,obesity,tobacco,typea,ldl),data=trainSA,method='glm',famili='binomial')
modelfit<-train(y=chd,x=c(age,alcohol,obesity,tobacco,typea,ldl),data=trainSA,method='glm',famili='binomial')
names(trainSC)
names(trainSA)
modelfit<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method='glm',family='binomial')
modelfit<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method='glm',family='binomial')
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
missClass(trainSA$chd, predict(modelfit, trainSA))
missClass(testSA$chd, predict(modelfit, trainSA))
missClass(testSA$chd, predict(modelfit, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
names(vowel.test)
vowel.test$y<-as.factor(vowel.test$y)
vowel.train$y<-as.factor(vowel.train$y)
set.seed(33833)
modelfit<-train(y~.,method="rf",data=vowel.train)
library('randomForest')
modelfit<-randomForest(y~.,data=vowel.train)
?varImp
varImp(modelfit)
order(varImp(modelfit))
order(varImp(modelfit),descending)
?order
order(varImp(modelfit),decreasing = T)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
mod1<-train(y~.,data=vowel.train,method="rf")
library(caret)
mod1<-train(y~.,data=vowel.train,method="rf")
mod2<-train(y~.,data=vowel.train,method="gbm")
mod2<-train(y~.,data=vowel.train,method="gbm")
pred1<-predict(mod1,vowel.test)
pred2<-predict(mod2,vowel.test)
predDF<-data.frame
predDF<-data.frame(pred1,pred2,y=vowel.test$y)
combModFit<-train(y~.,data=predDF,method="gam")
combPred<-predict(combModFit,predDF)
sqrt(sum((pred1-vowel.test$y)^2))
sqrt(sum((pred2-vowel.test$y)^2))
sqrt(sum((combPred-vowel.test$y)^2))
class(pred1)
class(vowel.test$y)
sqrt(sum((as.numeric(pred1)-as.numeric(vowel.test$y))^2))
confusionMatrix(vowel.test$y,pred1)
confusionMatrix(vowel.test$y,pred2)
sum(pred1[predDF$pred1 == predDF$pred2] ==
predDF$y[predDF$pred1 == predDF$pred2]) /
sum(predDF$1 == predDF$2)
sum(pred1[predDF$pred1 == predDF$pred2] ==
predDF$y[predDF$pred1 == predDF$pred2]) /
sum(predDF$pred1 == predDF$pred2)
sum(pred1[pred1==pred2]==predDF$y[pred1==pred2])/sum(pred1==pred2)
head(pred1[predDF$pred1 == predDF$pred2])
pred1[pred1==pred2]
predDF$y[pred1==pred2]
pred1[pred1==pred2]==predDF$y[pred1==pred2]
pred1[pred1==pred2]
predDF$y[pred1==pred2]
sum(pred1[pred1==pred2]==predDF$y[pred1==pred2])/sum(pred1==pred2)
confusionMatrix(vowel.test$y,pred2)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod1<-train(diagnosis~.,data=training,method="rf")
mod2<-train(diagnosis~.,data=training,method="gbm")
mod3<-train(diagnosis~.,data=training,method="lda")
pred1<-predict(mod1,testing)
pred2<-predict(mod2,testing)
pred3<-predict(mod3,testing)
predDF<-data.frame(pred1,pred2,pred3,testing$diagnosis)
combmod<-train(diagnosis~.,data=predDF,method="rf")
str(predDF)
combmod<-train(diagnosis~.,data=predDF,method="rf")
predDF<-data.frame(pred1,pred2,pred3,diagnosis=testing$diagnosis)
combmod<-train(diagnosis~.,data=predDF,method="rf")
combpred<-predict(combmod,testing)
combpred<-predict(combmod,predDF)
confusionMatrix(pred1,testing$diagnosis)
confusionMatrix(pred2,testing$diagnosis)
confusionMatrix(pred3,testing$diagnosis)
confusionMatrix(combpred,testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
setwd('/home/vanniagm/drop/Dropbox/DataScience/Coursera/Machine Learning/')
render('index.Rmd')
libray(rmarkdown)
library(rmarkdown)
render('index.Rmd')
pred2
length(pred2)
length(testing1.1$classe)
str(pred2)
head(pred2)
modelFit2
p2<-read.csv('pred2.csv')
str(p2)
length(testing1.1$classe)
str(testing1.1)
length(p2$x)
length(p2$X)
head(X2)
head(p2$X)
tail(p2$X)
render('index.Rmd')
